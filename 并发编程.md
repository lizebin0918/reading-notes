## 并发编程

### JVM:内存结构
* metaspace:方法区，static变量
* 堆:实例对象
* 栈:线程工作区
* 程序计数器:当前线程执行到的对应行数
* 本地方法栈:native方法

### Java对象模型
* 对象头+实例数据

### JMM:Java内存模型-Java Memory Model
* 这是一个规范
* 工具类和关键字的原理
	* `volatile/synchronized/Lock`原理都是JMM
* 主要体现在：重排序、可见性、原子性

* 为什么需要内存模型？
	> 比如C语言就不存在内存模型的概念，依赖处理器，不同处理器结果会不一样，无法保证并发安全。需要有一个标准，让多线程运行的结果可预期。需要各个JVM来遵守这个规范，屏蔽硬件或者运行环境的差异化，主要受益者是我们开发者。
	> 如果没有这样的一个JMM内存模型来规范，那么很可能经过了不同JVM的不同规范的重排序之后，导致不同的虚拟机上运行饿结果会不一样，这样就会导致问题

* 重排序
	* 重排序带来的好处

	```java
	a = 3;//load a;set to 3;store a;-->load a;set to 3;set to 4;store a;
	b = 2;//load b;set to 2;store b;-->load b;set to 2;store b;
	a = a + 1;//load a;set to 4;store a;-->
	```

	* 编译器优化：JVM，JIT编译器
	* CPU指令重排

* 可见性
  
  * CPU->寄存器->L1 cache(分成10个，每个10%)->L2 cache(分成5个，每个20%)->L3 cache(100%) -- 越靠近CPU的速度越快，L1缓存L2的内容，L2缓存L3的内容，所以导致了各个CPU的变量值不一样
  * 所以需要有一个标准，让多线程运行的结果是可预期的
  * **线程间的对于共享变量的可见性问题，不是直接由多核引起的，而是由多缓存引起的**
  * 如果所有CPU都只用一个缓存，那么就不存在内存可见性问题
  * 每个CPU都会将自己需要的数据读到对应的L1/L2/L3缓存中，数据修改后也是写入缓存中，然后等待刷入到主存中。（还有总线呢...别忘了）
  * Java衍生出**主内存**和**本地内存**（这个本地内存不是线程的本地内存，而是CPU的L1/L2/L3的抽象），JVM只管主内存和本地内存即可
  * 作为程序开发者，不用关注底层的缓存细节，只关注两层内存即可
  * JMM对于本地内存和主内存的规定
      * **所有的变量都存储在主内存中，每个线程都有自己的工作内存，工作内存的变量实际是主内存中的拷贝**（变量在主内存）
      * **线程不能直接读写主存中的变量，而是只能操作自己工作内存中的变量，然后再同步到主内存中**（从主存读到本地内存，从本地内存写到主存）
      * **主内存是多个线程共享的，但线程间不共享工作内存，如果线程间需要通信，必须借助主内存中转来完成**（各线程的工作内存相互隔离，只能通过主存通信）
      
  * happens-before规则是用来解决可见性问题的：在时间上，动作A发生在动作B之前，B保证能看见A的变更
  * 如果第一个操作happens-before于另一个操作，那么第一个操作对于第二个操作是可见的

  ```java
  int a = 1;//成员变量
  public void change() { a=3;b=a; }//这个时候A线程读取b的值有可能等于1，表示a的修改对A线程不可见，违反了happens-before原则
  ``` 
  
  * happens-before规则
    * 单线程规则
    
    > 保证之后的操作看到之前的操作变化，如果发生重排序，依然遵循这个原则
    
    * **锁操作（synchronized和Lock）**
    
    > 线程A加锁/解锁，线程B都可以看到A线程的操作：`test项目-com.lzb.happens_before.TestVolatile`
    
    * **volatile变量**
    
    > **只要有线程对volatile变量读取，在此变量修改之前的其他变量修改，对于后面线程来说都是可见的，所以volatile也保证了其他变量的可见性**
    
    * 线程启动
    * 线程join
    * 传递性
    * 中断
    * 构造方法
    * 工具类
    
    > CountDownLatch
    > Semaphore
    > Future
    > 线程池
    > CycliBarrier

### 死锁

* 死锁条件
    * 互斥条件：一个资源每次只能被一个进程使用。
    * 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
    * 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。
    * 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。
	
### 死锁解决

* 等待锁的时间设置为随机：tryLock(3, TimeUnit)，如果无法获取锁会自动释放
* 更改获取锁顺序
    * 模拟情景：AccountA给AccountB转账，同时AccountB给AccountA转账，需要对AccountA和AccountB上锁，必然发生死锁：
    
    ```java
    synchronized(转出账户) {
        //这里睡眠或者发生STW，会发生死锁
        synchronized(转入账户) {
            
        }
    }
    ```
    
    * 如何解决？
        * 利用System.identifyHashCode()比较，保证AB两个账户上锁的反向反转

